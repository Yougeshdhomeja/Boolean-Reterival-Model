{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PreProcessing\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "#this function remove stop word from text\n",
    "def Remove_Stopwords(text_tokenized):\n",
    "    text_without_sw=[token for token in text_tokenized if token.lower() not in stop_words]\n",
    "    return text_without_sw\n",
    "\n",
    "#this function Remove_Punctuation from text\n",
    "def Remove_Punctuation(text_tokenized_wsw):\n",
    "    text_without_pun=[token for token in text_tokenized_wsw if token not in punctuations]\n",
    "    return text_without_pun\n",
    "\n",
    "#this Function coverts letters into lower.\n",
    "def casefolding(text):\n",
    "    text_casefolded=[]\n",
    "    for token in text:\n",
    "        text_casefolded.append(token.lower())\n",
    "    return text_casefolded\n",
    "\n",
    "\n",
    "#this function stem the words by porter stemmer\n",
    "def stemming_words(text):\n",
    "    stemmed_words=[]\n",
    "    for token in text:\n",
    "        stemmed_words.append(porter.stem(token))\n",
    "    return stemmed_words\n",
    "\n",
    "#this word tokenize the text into words and replace - with space\n",
    "def word_tokenization(data):\n",
    "    data=data.lower()\n",
    "    \n",
    "    characters=\"abcdefghijklmnopqrstuvwxyz\"\n",
    "    \n",
    "    special_character=['\\n',' ']\n",
    "    \n",
    "    for i in data:\n",
    "        if i == '-':\n",
    "            data=data.replace(i,\" \")\n",
    "        if i not in characters:\n",
    "            if i not in special_character:\n",
    "                data=data.replace(i,\"\")\n",
    "    data=data.split()\n",
    "    return(data)\n",
    "#this function write inverted_index_to_file\n",
    "def Write_inverted_index_to_file(inverted_index):\n",
    "    sorted_inverted_index = {}\n",
    "    sorted_inverted_index_keys = sorted(inverted_index.keys())  \n",
    "\n",
    "    for term in sorted_inverted_index_keys:\n",
    "        sorted_inverted_index[term] = inverted_index[term]\n",
    "    file = open(\"inverted_index.pkl\", \"wb\")\n",
    "    pickle.dump(sorted_inverted_index, file)\n",
    "    file.close()\n",
    "    \n",
    "    \n",
    "#check the Validity of the Query\n",
    "def check_query_valid_or_not(Query,no_of_terms):\n",
    "    if no_of_terms==1:\n",
    "        \n",
    "        if len(Query)==2:\n",
    "            if(str(Query[0]).lower()==\"not\"):\n",
    "                return 1\n",
    "            else:\n",
    "                if str(Query[0]).lower()!=\"not\":\n",
    "                    return 0\n",
    "    \n",
    "    \n",
    "    if no_of_terms==2:\n",
    "        if(str(Query[0]).lower()==\"not\"):\n",
    "            if ((str(Query[2]).lower()==\"and\") or (str(Query[2]).lower()==\"or\")):\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        if(str(Query[0]).lower()!=\"not\"):\n",
    "            if ((str(Query[1]).lower()==\"and\") or (str(Query[1]).lower()==\"or\")):\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "    if no_of_terms==3:\n",
    "        \n",
    "        if(str(Query[0]).lower()==\"not\"):\n",
    "            if ((str(Query[2]).lower()==\"and\") or (str(Query[2]).lower()==\"or\")):\n",
    "                if(str(Query[3]).lower()==\"not\"):\n",
    "                    if ((str(Query[5]).lower()==\"and\") or (str(Query[5]).lower()==\"or\")):\n",
    "                        return 1\n",
    "                    else:\n",
    "                        return 0\n",
    "                else:\n",
    "                    if(str(Query[3]).lower()!=\"not\"):\n",
    "                        if ((str(Query[4]).lower()==\"and\") or (str(Query[4]).lower()==\"or\")):\n",
    "                            return 1\n",
    "                        else:\n",
    "                            return 0      \n",
    "            else:\n",
    "                return 0\n",
    "        else:\n",
    "             if(str(Query[0]).lower()!=\"not\"):\n",
    "                    if ((str(Query[1]).lower()==\"and\") or (str(Query[1]).lower()==\"or\")):\n",
    "                        if(str(Query[2]).lower()==\"not\"):\n",
    "                            if ((str(Query[4]).lower()==\"and\") or (str(Query[4]).lower()==\"or\")):\n",
    "                                return 1\n",
    "                            else:\n",
    "                                return 0\n",
    "                        else:\n",
    "                            if(str(Query[2]).lower()!=\"not\"):\n",
    "                                if ((str(Query[3]).lower()==\"and\") or (str(Query[3]).lower()==\"or\")):\n",
    "                                       return 1\n",
    "                                else:\n",
    "                                    return 0\n",
    "                                \n",
    "                            \n",
    "                    else:\n",
    "                        return 0\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stemmed_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-bada1fb9e73f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mtext_cleaned\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRemove_Punctuation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_without_sw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m    \u001b[1;31m#call the function of casefolding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mtext_casefolded\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcasefolding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstemmed_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;31m#call the function to stem\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mstemmed_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstemming_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_cleaned\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stemmed_words' is not defined"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "#open file of stop_words\n",
    "file=open(\"C:\\\\Users\\\\Yougesh\\\\CS317-IR Dataset for A1\\\\Stopword-List.txt\",'r')\n",
    "#read file of stop_words\n",
    "\n",
    "stop_words=file.read()\n",
    "\n",
    "#punctuations tobe removed\n",
    "punctuations = '''!()-[]{};:'‘\"\\,<>./?@#$%^&*“’”_~'''\n",
    "\n",
    "\n",
    "inverted_index=dict()\n",
    "\n",
    "list_t=\"\"\n",
    "for x in range(1,51):\n",
    "    #file opening one by one\n",
    "    file=open(\"C:\\\\Users\\\\Yougesh\\\\CS317-IR Dataset for A1\\\\ShortStories\\\\\"+str(x)+\".txt\",'r',encoding=\"utf8\")\n",
    "    \n",
    "    data=file.read()\n",
    "    #call the word_tokenization function\n",
    "    tokenized_text=word_tokenization(data)\n",
    "    #call the function to remove stop words\n",
    "    text_without_sw=Remove_Stopwords(tokenized_text)\n",
    "    #call the function to remove punctuation.\n",
    "    text_cleaned=Remove_Punctuation(text_without_sw)\n",
    "   #call the function of casefolding\n",
    "    text_casefolded=casefolding(stemmed_words)\n",
    "    #call the function to stem\n",
    "    stemmed_words=stemming_words(text_cleaned)\n",
    "    \n",
    "   #Building Inverted_Index\n",
    "    if x==1:\n",
    "        for token in stemmed_words:\n",
    "            inverted_index[token]=[]\n",
    "            inverted_index[token].append(x)\n",
    "    else:\n",
    "        list_keys=inverted_index.keys()\n",
    "        for token in stemmed_words:\n",
    "            if token not in list_keys:\n",
    "                inverted_index[token]=[]\n",
    "        for token in stemmed_words:\n",
    "                if token in list_keys:\n",
    "                    if x not in inverted_index.get(token):\n",
    "                        inverted_index[token].append(x)\n",
    "\n",
    "#call the function to write an inverted index to file\n",
    "Write_inverted_index_to_file(inverted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Query:god and man and love\n",
      "Result-Set:[1, 2, 4, 7, 8, 9, 14, 16, 19, 22, 23, 24, 25, 26, 27, 28, 31, 38, 46]\n"
     ]
    }
   ],
   "source": [
    "#Query processing.\n",
    "\n",
    "#Loading invertedIndex in dictionary_object.\n",
    "file = open(\"inverted_index.pkl\", \"rb\")\n",
    "inverted_index = pickle.load(file)\n",
    "#operators tobe used in query\n",
    "Operators=['not','and','or']\n",
    "#list docID contains an list of all docID's\n",
    "docID=[]\n",
    "for i in range(1,51):\n",
    "    docID.append(i)\n",
    "\n",
    "Query=input(\"Enter the Query:\")\n",
    "\n",
    "Query=Query.split()\n",
    "\n",
    "final_res=[]\n",
    "#finding the no of terms in the Query\n",
    "no_of_terms=[term for term in Query if term not in Operators]\n",
    "#check wheter Query is valid or not\n",
    "if check_query_valid_or_not(Query,len(no_of_terms))==0:\n",
    "    print(\"Invalid Query Syntax\")\n",
    "    sys.exit()\n",
    "    \n",
    "#if there is one term in the Query\n",
    "if len(no_of_terms)==1:\n",
    "    res=[]\n",
    "    for term in no_of_terms:\n",
    "        if porter.stem(term.lower()) in inverted_index:\n",
    "            res=inverted_index.get(porter.stem(term.lower()))\n",
    "        #if Query contain not\n",
    "        if len(Query)==2:\n",
    "                res=[term for term in docID if term not in res]\n",
    "    final_res=res\n",
    "\n",
    "    \n",
    "#If there is two terms in the Query\n",
    "if len(no_of_terms)==2:\n",
    "    res1=[]\n",
    "    res2=[]\n",
    "    operator_index=0\n",
    "    #if there is not with the first term\n",
    "    if(str(Query[0]).lower()==\"not\"):\n",
    "        #if the term in the inverted_index\n",
    "        if porter.stem(Query[1].lower()) in inverted_index:\n",
    "                res1=inverted_index.get(porter.stem(Query[1].lower()))\n",
    "        res1=[term for term in docID if term not in res1]\n",
    "        operator_index=2\n",
    "    elif (str(Query[0]).lower()!=\"not\"): \n",
    "        if porter.stem(Query[0].lower()) in inverted_index:\n",
    "                res1=inverted_index.get(porter.stem(Query[0].lower()))\n",
    "        operator_index=1\n",
    "    if(str(Query[operator_index+1]).lower()==\"not\"):\n",
    "        if porter.stem(Query[operator_index+2].lower()) in inverted_index:\n",
    "            res2=inverted_index.get(porter.stem(Query[operator_index+2].lower()))\n",
    "        res2=[term for term in docID if term not in res2]\n",
    "    elif(str(Query[operator_index+1]).lower()!=\"not\"):\n",
    "        if porter.stem(Query[operator_index+1].lower()) in inverted_index:\n",
    "            res2=inverted_index.get(porter.stem(Query[operator_index+1].lower()))\n",
    "    #if Query Contain and operator in between\n",
    "    if(str(Query[operator_index]).lower()==\"and\"):\n",
    "        #if res1 has less posting list\n",
    "        if(len(res1)<len(res2)):\n",
    "            final_res=[term for term in res1 if term in res2]\n",
    "        else:\n",
    "            final_res=[term for term in res2 if term in res1]\n",
    "    if(str(Query[operator_index]).lower()==\"or\"):\n",
    "        final_res=list(set().union(res1,res2))\n",
    "        \n",
    "#Query Processing when no od terms are three.\n",
    "if len(no_of_terms)==3:\n",
    "    res1=[]\n",
    "    res2=[]\n",
    "    res3=[]\n",
    "    operator_index1=0\n",
    "    operator_index2=0\n",
    "    if(str(Query[0]).lower()==\"not\"):\n",
    "        if porter.stem(Query[1].lower()) in inverted_index:\n",
    "            res1=inverted_index.get(porter.stem(Query[1].lower()))\n",
    "        res1=[term for term in docID if term not in res1]\n",
    "        operator_index1=2\n",
    "    elif (str(Query[0]).lower()!=\"not\"):\n",
    "        if porter.stem(Query[0].lower()) in inverted_index:\n",
    "                res1=inverted_index.get(porter.stem(Query[0].lower()))\n",
    "        operator_index1=1\n",
    "    if(str(Query[operator_index1+1]).lower()==\"not\"):\n",
    "        if porter.stem(Query[operator_index1+2].lower()) in inverted_index:\n",
    "            res2=inverted_index.get(porter.stem(Query[operator_index1+2].lower()))\n",
    "        res2=[term for term in docID if term not in res2]\n",
    "        operator_index2=operator_index1+3\n",
    "    elif(str(Query[operator_index1+1]).lower()!=\"not\"):  \n",
    "        if porter.stem(Query[operator_index1+1].lower()) in inverted_index:\n",
    "            res2=inverted_index.get(porter.stem(Query[operator_index1+1].lower())) \n",
    "        operator_index2=operator_index1+2\n",
    "    if(str(Query[operator_index2+1]).lower()==\"not\"):\n",
    "        if porter.stem(Query[operator_index2+2].lower()) in inverted_index:\n",
    "                res3=inverted_index.get(porter.stem(Query[operator_index2+2].lower()))\n",
    "        res3=[term for term in docID if term not in res3]\n",
    "    elif(str(Query[operator_index2+1]).lower()!=\"not\"):\n",
    "        if porter.stem(Query[operator_index2+1].lower()) in inverted_index:\n",
    "            res3=inverted_index.get(porter.stem(Query[operator_index2+1].lower()))\n",
    "    \n",
    "    if(str(Query[operator_index1]).lower()==\"and\"):\n",
    "        if(len(res1)<len(res2)):\n",
    "            res2=[term for term in res1 if term in res2]\n",
    "        else:\n",
    "            res2=[term for term in res2 if term in res1]\n",
    "        if (str(Query[operator_index2]).lower()==\"and\"):\n",
    "            if(len(res2)<len(res3)):\n",
    "                final_res=[term for term in res2 if term in res3]\n",
    "            else:\n",
    "                final_res=[term for term in res3 if term in res2]\n",
    "        else:\n",
    "            final_res=list(set().union(res2,res3))\n",
    "    if(str(Query[operator_index1]).lower()==\"or\"):\n",
    "        res2=list(set().union(res1,res2))\n",
    "        if (str(Query[operator_index2]).lower()==\"and\"):\n",
    "            if(len(res2)<len(res3)):\n",
    "                final_res=[term for term in res2 if term in res3]\n",
    "            else:\n",
    "                final_res=[term for term in res3 if term in res2]\n",
    "        else:\n",
    "             final_res=list(set().union(res2,res3))\n",
    "    \n",
    "print(\"Result-Set:\"+str(final_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
